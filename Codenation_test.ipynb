{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codenation test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6bYM2kuMds2NCs4zesGMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdurbano/Machine-Learning/blob/master/Codenation_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZNQf6ZGZ_lm",
        "colab_type": "code",
        "outputId": "9dd5e3df-0ce3-4c52-b044-903879ffbe41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6mX3rAbvqyL",
        "colab_type": "text"
      },
      "source": [
        "# **Importando as bibliotecas base**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDpQ-22-aDPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import math\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg30SmEyvvPB",
        "colab_type": "text"
      },
      "source": [
        "# **Importando DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wkCyKQKaJ-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filePath = \"/content/drive/My Drive/Codenation/train.csv\"\n",
        "df = pd.read_csv(filePath, delimiter=\",\", encoding=\"UTF8\")\n",
        "\n",
        "filePath = \"/content/drive/My Drive/Codenation/test.csv\"\n",
        "dfTest = pd.read_csv(filePath, delimiter=\",\", encoding=\"UTF8\")\n",
        "\n",
        "colunasSelecionadas = list(dfTest.columns)\n",
        "colunasSelecionadas.append('NU_NOTA_MT')\n",
        "\n",
        "df = df[colunasSelecionadas]\n",
        "\n",
        "dfresult = pd.DataFrame()\n",
        "dfresult['NU_INSCRICAO'] = dfTest['NU_INSCRICAO'] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oryiz5O_v7Ce",
        "colab_type": "text"
      },
      "source": [
        "# **Aplicando LABEL ENCODER e ONE HOT ENCODER**\n",
        "\n",
        "Processo para transformar dados categóricos em numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIOlrq6OoxE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# DATA CLEASING\n",
        "\n",
        "for item in df.columns:\n",
        "  if item[0:3] == \"IN_\":\n",
        "    df[item] = df[item].astype(bool)\n",
        "\n",
        "df['TP_ENSINO'] = df['TP_ENSINO'].astype(float)\n",
        "df['TP_DEPENDENCIA_ADM_ESC'] = df['TP_DEPENDENCIA_ADM_ESC'].astype(float)\n",
        "df['Q027'] = df['Q027'].fillna('Z')\n",
        "\n",
        "\n",
        "features_list = ['NU_NOTA_CN','NU_NOTA_LC','NU_NOTA_CH','NU_NOTA_MT','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_REDACAO']\n",
        "def meanFill(data):\n",
        "    for item in features_list:\n",
        "        data[item] = data[item].fillna(data[item].mean())\n",
        "    return data\n",
        "\n",
        "\n",
        "df = df.fillna(0)\n",
        "\n",
        "#ONE HOT ENCODER\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "# for item in df.columns:\n",
        "#   if item[0:2] == 'Q0' or item == 'SG_UF_RESIDENCIA':\n",
        "#     enc_df = pd.DataFrame(enc.fit_transform(df[[item]]).toarray())\n",
        "#     colunasRenomear = {}\n",
        "#     for itemEncode in enc_df.columns:\n",
        "#       colunasRenomear[itemEncode] = item +  str(itemEncode)\n",
        "#     enc_df = enc_df.rename(columns=colunasRenomear)\n",
        "#     df = df.join(enc_df)\n",
        " \n",
        "# LABEL ENCODER\n",
        "for item in df.columns:\n",
        "  if item[0:2] == 'Q0' or item[0:3] == 'CO_' or item == 'SG_UF_RESIDENCIA' or item == 'TP_SEXO':\n",
        "    df[item] = labelencoder.fit_transform(df[item])\n",
        "\n",
        "# CONVERSOES\n",
        "df['TP_SEXO'] = df['TP_SEXO'].astype(bool)\n",
        "\n",
        "# DATA CLEASING\n",
        "colDel = ['NU_INSCRICAO']\n",
        "df.drop(colDel, axis = 1, inplace = True) # 'axis' = 0 (row) | axis = 1 (column)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJtkCfhJwTA9",
        "colab_type": "text"
      },
      "source": [
        "# **Função para EDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21h0U9PEkEXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def EDA_Codenation (dataSet):\n",
        "  sns.set(style=\"whitegrid\")\n",
        "\n",
        "  # the histogram of the data\n",
        "  fig, ax = plt.subplots(figsize= (16, 5))\n",
        "  ax = sns.distplot(dataSet.NU_NOTA_MT,ax=ax)\n",
        "\n",
        "  # Boxplot (Seaborn)\n",
        "  plt.figure(figsize=(16, 5))\n",
        "  ax = sns.boxplot(x=dataSet[\"NU_NOTA_MT\"],width=20)\n",
        "\n",
        "  #matriz de correlação\n",
        "  plt.figure(figsize=(40, 30))\n",
        "  corrMatrix = dataSet.corr()\n",
        "  sns.heatmap(corrMatrix, annot=True)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  #subplot\n",
        "  fig, ax = plt.subplots(math.ceil(df.shape[1] /3 ), 3, figsize = (40, 50))\n",
        "  fig.tight_layout()\n",
        "  column =0\n",
        "  row =0\n",
        "  for item in dataSet.columns:\n",
        "      sns.distplot(dataSet[item],ax = ax[row, column])\n",
        "      column+=1\n",
        "      if column == 3:\n",
        "        column = 0\n",
        "        row+=1\n",
        "\n",
        "\n",
        "EDA_Codenation(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlYf7ke2wibX",
        "colab_type": "text"
      },
      "source": [
        "# **Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfCQw1kA-lgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colManter = ['CO_UF_RESIDENCIA','SG_UF_RESIDENCIA','TP_SEXO','NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_REDACAO','Q001','Q002','Q006','Q024','Q025','Q047','NU_NOTA_MT']\n",
        "#colManter = ['NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_REDACAO','NU_NOTA_MT']\n",
        "df = df[colManter]\n",
        "\n",
        "#EDA_Codenation(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNQAEVRtw_oQ",
        "colab_type": "text"
      },
      "source": [
        "## **Dataset de Treino - separando em Treino e Teste**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHGRg-yzA5qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separando PREDITORAS de TARGET\n",
        "X_preditoras = df.drop('NU_NOTA_MT', axis=1, inplace=False)\n",
        "Y_target = df['NU_NOTA_MT']\n",
        "\n",
        "# Separando dados de TREINO e TESTE\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X_preditoras, Y_target) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAF648qpxOwf",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset de Teste - Aplicando data quality**\n",
        "Utilizando o dataset de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jRJMchumXHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREPARACAO DO DADO DE TESTE\n",
        "\n",
        "#features_list = ['NU_NOTA_CN','NU_NOTA_LC','NU_NOTA_CH','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_REDACAO']\n",
        "#dfTest = meanFill(dfTest)\n",
        "#dfTest = dfTest.fillna(dfTest.mean())\n",
        "dfTest = dfTest.fillna(0)\n",
        "\n",
        "colManter = ['CO_UF_RESIDENCIA','SG_UF_RESIDENCIA','TP_SEXO','NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_REDACAO','Q001','Q002','Q006','Q024','Q025','Q047']\n",
        "dfTest = dfTest[colManter]\n",
        "\n",
        "# LABEL ENCODER\n",
        "for item in dfTest.columns:\n",
        "  if item[0:2] == 'Q0' or item[0:3] == 'CO_' or item == 'SG_UF_RESIDENCIA' or item == 'TP_SEXO':\n",
        "    dfTest[item] = labelencoder.fit_transform(dfTest[item])\n",
        "\n",
        "# CONVERSOES\n",
        "dfTest['TP_SEXO'] = dfTest['TP_SEXO'].astype(bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7FA1GG1xtnB",
        "colab_type": "text"
      },
      "source": [
        "# **Normalizando utilizando MinMaxScaler**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcPKFfweT_uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NORMALIZANDO\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Xtrain = min_max_scaler.fit_transform(Xtrain)  \n",
        "Xtest = min_max_scaler.transform(dfTest.values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUcvFlZGx4HP",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo de regressão Linear**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7GydA1vgu7z",
        "colab_type": "code",
        "outputId": "eba15b4c-6554-4d06-8f02-e6d9e6d75bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate \n",
        "\n",
        "#instaciar modelo\n",
        "kfold = KFold(n_splits=5, random_state=21, shuffle=True)\n",
        "modelLR = LinearRegression()\n",
        "modelLR.fit(Xtrain, ytrain)\n",
        "\n",
        "# Cross Validation\n",
        "resultado = cross_val_score(modelLR, Xtrain, ytrain, cv = kfold , scoring='neg_mean_squared_error')\n",
        "\n",
        "# Print do resultado\n",
        "msg = \"%s | Erro médio: %f       Check: (%f)\" % ('LinearRegression', resultado.mean(), resultado.std())\n",
        "print(msg)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression | Erro médio: -4497.044003       Check: (134.613693)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8xkGNPbyCJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7ocL6mRyDAf",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo de Gradient Boosting**\n",
        "\n",
        "The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
        "\n",
        "Two families of ensemble methods are usually distinguished:\n",
        "\n",
        "In averaging methods, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.\n",
        "\n",
        "Examples: Bagging methods, Forests of randomized trees, …\n",
        "\n",
        "By contrast, in boosting methods, base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.\n",
        "\n",
        "Examples: AdaBoost, Gradient Tree Boosting, …\n",
        "\n",
        "[link text](https://scikit-learn.org/stable/modules/ensemble.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km39SFFEngzO",
        "colab_type": "code",
        "outputId": "4a240f0c-6201-4cf7-8024-c4e5caea1342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import dos módulos\n",
        "from sklearn.model_selection import KFold,RandomizedSearchCV,cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Criando o modelo\n",
        "kfold = KFold(n_splits=5, random_state=21, shuffle=True)\n",
        "modelGBR = GradientBoostingRegressor()\n",
        "modelGBR.fit(Xtrain, ytrain)\n",
        "\n",
        "# Cross Validation\n",
        "resultado = cross_val_score(modelGBR, Xtrain, ytrain, cv = kfold , scoring='neg_mean_squared_error')\n",
        "\n",
        "# Print do resultado\n",
        "msg = \"%s | Erro médio: %f       Check: (%f)\" % ('LinearRegression', resultado.mean(), resultado.std())\n",
        "print(msg)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression | Erro médio: -4105.635497       Check: (131.036466)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcMKT50nzIP5",
        "colab_type": "text"
      },
      "source": [
        "GBM utilizando Pipeline e RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-CePhTdy4GZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold,RandomizedSearchCV,cross_val_score\n",
        "\n",
        "pipe_GBM = Pipeline([('scaler',  StandardScaler()),\n",
        "            ('GradientBoostingRegressor', GradientBoostingRegressor())])\n",
        "\n",
        "CV_pipe_GBM = RandomizedSearchCV(estimator = pipe_GBM, param_distributions = {},cv = 5,return_train_score=True, verbose=0)\n",
        "\n",
        "CV_pipe_GBM.fit(X_preditoras, Y_target)\n",
        "\n",
        "#predizendo em cima da base de teste\n",
        "ypred = CV_pipe_GBM.predict(dfTest)\n",
        "\n",
        "#depositando no dataset de resultado\n",
        "dfresult['NU_NOTA_MT'] = np.around(ypred,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW2f_5DRzaTs",
        "colab_type": "text"
      },
      "source": [
        "# **Modelo de Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm9jedRlu8M3",
        "colab_type": "code",
        "outputId": "d05ba11f-1a6e-4e2a-f965-957337c808b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import dos módulos\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Criando o modelo\n",
        "kfold = KFold(n_splits=5, random_state=21, shuffle=True)\n",
        "modelRFR = RandomForestRegressor()\n",
        "modelRFR.fit(Xtrain, ytrain)\n",
        "\n",
        "# Cross Validation\n",
        "resultado = cross_val_score(modelRFR, Xtrain, ytrain, cv = kfold , scoring='neg_mean_squared_error')\n",
        "\n",
        "# Print do resultado\n",
        "msg = \"%s | Erro médio: %f       Check: (%f)\" % ('LinearRegression', resultado.mean(), resultado.std())\n",
        "print(msg)\n",
        "\n",
        "ypred = modelGBR.predict(Xtest)\n",
        "dfresult['NU_NOTA_MT'] = np.around(ypred,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression | Erro médio: -4372.788448       Check: (135.066998)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtmRfQ0Izlvf",
        "colab_type": "text"
      },
      "source": [
        "# **Exportação do DataSet para CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tKKQsvfrZqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfresult.to_csv('codenationResposta.csv', index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}